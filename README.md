# DeepSPIRE

**TensorFlow Implementation**

Paper Link will be updated upon publication.

This repository contains the code and data to reproduce the results of the paper:
**"Super-resolving Herschel - a deep learning based deconvolution
and denoising technique I."** by Koopmans et al 2025, published in [TBD].

## üìå Abstract
Aims. Dusty star-forming galaxies (DSFG) dominate the far-infrared (FIR) and sub-millimetre (sub-mm) number counts, but single-
dish surveys at these wavelengths suffer from poor angular resolution, making identifications of multi-wavelength counterparts diffi-
cult. Prior-driven deblending techniques require extensive fine-tuning and struggle to process large fields. This work aims to develop
a fast and reliable deep-learning based deconvolution and denoising super-resolution (SR) technique.

Methods. We employ a transformer neural network to improve the resolution of the Herschel/SPIRE 500 Œºm observations by a
factor of 4.5, with input comprised of Spitzer/MIPS 24Œºm and Herschel/SPIRE 250, 350, 500Œºm images. The network was trained on
simulations from SIDES and SHARK. To mimic realistic observations, we injected instrumental noise into the input simulated images,
while keeping the target images noise-free to enhance the de-noising capabilities of our method. We evaluated the performance of our
method on simulated test sets and real JCMT/SCUBA-2 450 Œºm observations in the COSMOS field which have superior resolution
compared to Herschel.

Results. Our SR method achieves an inference time of ‚àº 1s/deg2 on consumer-grade GPUs, much faster than traditional deblending
techniques. Using the simulation test sets, we show that fluxes of the extracted sources from the super-resolved image are accurate
to within 5% for sources with an intrinsic flux ‚â≥ 8 mJy, which is a substantial improvement compared to blind extraction on the
native images. Astrometric error is low, at 1‚Ä≤‚Ä≤compared to the 12‚Ä≤‚Ä≤pixel scale. In terms of reliability and completeness, ‚â≥ 90% of
the extracted sources brighter than ‚àº 3 mJy are reliable and more than 90% of the input sources with intrinsic fluxes ‚â≥ 6 mJy are
recovered. When applied to the real 500 Œºm observations, the fluxes of the extracted sources from the super-resolved map agree well
with the SCUBA-2 measured fluxes (after converting the 450 Œºm fluxes to 500 Œºm using a correction factor of 0.84) for sources above
‚àº 10 mJy. Our 500 Œºm number counts are also consistent with previous SCUBA-2 measurements. Thanks to its speed, our technique
enables SR over hundreds of deg2 without the need for fine-tuning, facilitating statistical analysis of DSFGs.

---


## üõ† Installation

### 1. Clone the repository
```bash
git clone https://github.com/dennmartko/DeepSPIRE.git
cd DeepSPIRE
```

## 2. Create a virtual environment (optional but recommended)
```bash
python3 -m venv venv
source venv/bin/activate
```

Main requirements:
- Python 3.10-3.12
- pySIDES (for data preparation)
- TensorFlow 2.2.x (GPU version required)
- For Training: NVIDIA GPU with at least 40GB VRAM
- For Inference: NVIDIA GPU with at least 8GB VRAM

DeepSPIRE uses TensorFlow with GPU acceleration. To ensure proper GPU support, you need a compatible NVIDIA GPU, CUDA Toolkit, and cuDNN installed on your system. For more details on installing CUDA and cuDNN, see the official NVIDIA guides and TensorFlow GPU setup.

## 3. Install dependencies & DeepSPIRE
```bash
pip install -r requirements.txt
pip install -e .
```

## ‚ôªÔ∏è Reproducing results

### üìÇ Data Preparation
1. Download the pySIDES Uchuu dataset from https://data.lam.fr/sides/search/dataset. We used all catalogs upto and including tile_6_8.
2. Use pySIDES to generate simulated catalogs containing Herschel 250, 350 and 500 Œºm and Spitzer MIPS 24 Œºm fluxes as well as the source coordinates. Follow the instructions in the pySIDES documentation: https://gitlab.lam.fr/mbethermin/sides-public-release.
3. Download the SHARK lightcone catalogs (Private communication with A. Lagos). One can also train with only the Uchuu dataset from pySIDES.
4. 




Alternative symbols you can use: ‚ôªÔ∏è  üîÅ  üî¨  ‚úÖ  üß™

